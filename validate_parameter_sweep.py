#!/usr/bin/env python3
"""
Parameter Sweep Validation Analysis

Analyzes existing parameter sweep results to validate:
1. Output files contain real data
2. Parameter variations produce different results
3. Framework can generate multiple successful runs
4. Data quality and completeness
"""

import os
import json
import pandas as pd
import numpy as np
from pathlib import Path

def analyze_existing_results():
    """Analyze existing parameter sweep results"""
    
    print("ğŸ” PARAMETER SWEEP VALIDATION ANALYSIS")
    print("=" * 60)
    
    # Check existing results
    results_dir = Path("/Users/kaimyers/PygemRound2/parameter_sweep/results")
    
    if not results_dir.exists():
        print("âŒ No parameter sweep results directory found")
        return
    
    # Find successful runs (those with .nc files)
    successful_runs = []
    failed_runs = []
    
    for run_dir in sorted(results_dir.glob("run_*")):
        run_id = int(run_dir.name.split('_')[1])
        
        # Check for NetCDF output files
        nc_files = list(run_dir.glob("*.nc"))
        
        if nc_files:
            successful_runs.append((run_id, run_dir, nc_files))
        else:
            failed_runs.append((run_id, run_dir))
    
    print(f"ğŸ“Š SUMMARY:")
    print(f"   Total run directories: {len(list(results_dir.glob('run_*')))}")
    print(f"   âœ… Successful runs: {len(successful_runs)}")
    print(f"   âŒ Failed runs: {len(failed_runs)}")
    print(f"   Success rate: {len(successful_runs)/(len(successful_runs)+len(failed_runs))*100:.1f}%")
    
    if not successful_runs:
        print("âŒ No successful runs found - parameter sweep framework has issues")
        return
    
    print(f"\nğŸ¯ SUCCESSFUL RUNS ANALYSIS:")
    
    # Load parameter information
    try:
        df = pd.read_csv("/Users/kaimyers/PygemRound2/parameter_sweep/parameter_sweep_summary.csv")
        print(f"   Parameters file loaded: {len(df)} parameter combinations")
    except:
        print("   âš ï¸ Could not load parameter summary file")
        df = None
    
    # Analyze each successful run
    run_data = []
    
    for run_id, run_dir, nc_files in successful_runs:
        print(f"\n   Run {run_id:04d}:")
        print(f"      ğŸ“ Directory: {run_dir}")
        print(f"      ğŸ“„ Output files: {len(nc_files)}")
        
        # Get parameter information
        if df is not None and run_id < len(df):
            params = df.iloc[run_id]
            print(f"      ğŸ”§ Parameters: tbias={params['tbias']}, kp={params['kp']}, ddf={params['ddfsnow']}")
            
            # Try to analyze the output data
            try:
                import netCDF4 as nc
                
                # Find the main stats file
                stats_files = [f for f in nc_files if 'all.nc' in f.name]
                if stats_files:
                    with nc.Dataset(stats_files[0], 'r') as ds:
                        # Check available variables
                        variables = list(ds.variables.keys())
                        print(f"      ğŸ“‹ Variables: {len(variables)} available")
                        
                        # Get glacier area data if available
                        if 'glac_area_annual' in ds.variables:
                            area_data = ds.variables['glac_area_annual'][0, :] / 1e6  # Convert to kmÂ²
                            initial_area = area_data[0] if area_data[0] > 0 else area_data[1]
                            final_area = area_data[-1]
                            area_loss_pct = (initial_area - final_area) / initial_area * 100
                            
                            print(f"      ğŸ”ï¸ Initial area: {initial_area:.2f} kmÂ²")
                            print(f"      ğŸ”ï¸ Final area: {final_area:.2f} kmÂ²")
                            print(f"      ğŸ“‰ Area loss: {area_loss_pct:.1f}%")
                            
                            run_data.append({
                                'run_id': run_id,
                                'tbias': params['tbias'],
                                'kp': params['kp'],
                                'ddfsnow': params['ddfsnow'],
                                'initial_area': initial_area,
                                'final_area': final_area,
                                'area_loss_pct': area_loss_pct,
                                'output_files': len(nc_files)
                            })
                        
                        # Get discharge data if available
                        if 'glac_runoff_monthly' in ds.variables:
                            discharge_data = ds.variables['glac_runoff_monthly'][0, :]
                            max_discharge = np.max(discharge_data)
                            print(f"      ğŸ’§ Max discharge: {max_discharge:.2e} mÂ³/s")
                            
            except ImportError:
                print("      âš ï¸ netCDF4 not available for data analysis")
            except Exception as e:
                print(f"      âš ï¸ Data analysis error: {e}")
    
    # Compare results across different parameters
    if len(run_data) > 1:
        print(f"\nğŸ”¬ PARAMETER SENSITIVITY ANALYSIS:")
        
        run_df = pd.DataFrame(run_data)
        
        # Check if different parameters produce different results
        if len(run_df['final_area'].unique()) > 1:
            print("   âœ… Parameter variations produce different results")
            print(f"   ğŸ“Š Final area range: {run_df['final_area'].min():.2f} - {run_df['final_area'].max():.2f} kmÂ²")
            print(f"   ğŸ“Š Area loss range: {run_df['area_loss_pct'].min():.1f}% - {run_df['area_loss_pct'].max():.1f}%")
            
            # Show parameter correlations
            if 'tbias' in run_df.columns:
                tbias_range = run_df['tbias'].max() - run_df['tbias'].min()
                kp_range = run_df['kp'].max() - run_df['kp'].min()
                ddf_range = run_df['ddfsnow'].max() - run_df['ddfsnow'].min()
                
                print(f"   ğŸ”§ Parameter ranges tested:")
                print(f"      tbias: {tbias_range:.1f}Â°C range")
                print(f"      kp: {kp_range:.1f} range") 
                print(f"      ddfsnow: {ddf_range:.4f} range")
        else:
            print("   âš ï¸ All runs produced identical results - may indicate parameter range too narrow")
    
    # Check failure analysis
    if failed_runs:
        print(f"\nâŒ FAILURE ANALYSIS:")
        print(f"   {len(failed_runs)} runs failed")
        
        # Sample a few failed runs to understand issues
        sample_failed = failed_runs[:3]
        for run_id, run_dir in sample_failed:
            print(f"   Run {run_id:04d}:")
            
            # Check for run_info.json
            run_info_file = run_dir / "run_info.json"
            if run_info_file.exists():
                try:
                    with open(run_info_file, 'r') as f:
                        run_info = json.load(f)
                    
                    status = run_info.get('status', 'unknown')
                    error = run_info.get('error_msg', 'No error message')
                    print(f"      Status: {status}")
                    if 'error' in error.lower() or 'fail' in error.lower():
                        print(f"      Error: {error[:100]}...")
                        
                except Exception as e:
                    print(f"      Could not read run info: {e}")
    
    # Overall assessment
    print(f"\nğŸ¯ PARAMETER SWEEP FRAMEWORK ASSESSMENT:")
    
    success_rate = len(successful_runs)/(len(successful_runs)+len(failed_runs))
    
    if success_rate >= 0.8:
        print("   ğŸ‰ EXCELLENT! Parameter sweep framework is working well")
        print("   âœ… Ready for full-scale parameter sweep")
    elif success_rate >= 0.5:
        print("   âœ… GOOD! Parameter sweep framework is mostly functional")
        print("   âš ï¸ Some optimization may be needed for better reliability")
    elif success_rate >= 0.2:
        print("   âš ï¸ PARTIAL SUCCESS - Framework has significant issues")
        print("   ğŸ”§ Need to investigate and fix failure modes")
    else:
        print("   âŒ POOR PERFORMANCE - Major issues with parameter sweep")
        print("   ğŸš¨ Framework needs significant debugging")
    
    # Recommendations
    print(f"\nğŸ’¡ RECOMMENDATIONS:")
    
    if len(successful_runs) > 0:
        print("   âœ… Basic parameter sweep functionality is working")
        print("   âœ… PyGEM simulations can run with parameter variations")
        print("   âœ… Output files are generated and contain real data")
    
    if len(failed_runs) > len(successful_runs):
        print("   ğŸ”§ Fix config file management issues")
        print("   ğŸ”§ Improve error handling and recovery")
        print("   ğŸ”§ Add parameter validation")
    
    print("   ğŸ“‹ Use realistic parameter ranges for future sweeps")
    print("   ğŸ“‹ Implement better progress tracking")
    print("   ğŸ“‹ Add output validation checks")
    
    return {
        'total_runs': len(successful_runs) + len(failed_runs),
        'successful_runs': len(successful_runs),
        'failed_runs': len(failed_runs),
        'success_rate': success_rate,
        'run_data': run_data
    }

if __name__ == "__main__":
    results = analyze_existing_results()
    print("\nğŸ Parameter sweep validation completed!")